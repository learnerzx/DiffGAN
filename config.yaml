
                                    #Data parameters
dataset: "IXI"                                                      # Dataset type. currently only IXI supported.
train_data_dir: "data/h5_FastMRI_rd/train"                                    # Training files dir, should contain hdf5 preprocessed data.
val_data_dir: "data/h5_FastMRI_rd/val"                                        # Validation files dir, should contain hdf5 preprocessed data.
output_dir: "OUTPUT_PATH"                                           # Directory to save checkpoints and tensorboard data.
center_fractions: [0.08]
accelerations: [2]
seed: 10
sampling_percentage: 25                                             # Sampling mask precentage (provided with the code 20%,30% and 50% sampling masks of 256X256).
mask_type: Spiral                                                   # mask: Gaussian2D,Radial,Spiral,Random,Poisson
num_input_slices: 3                                                 # Num of slices to use for input (3 means the predicted slice + previous slice + next slice).
img_size: 256                                                       # Input image size (256X256 for IXI).
slice_range: [9,25]                                                 #  Slices to use for training FastMRI data.
#slice_range: [110,190]                                               #  Slices to use for training MICCAI 2013 data.
#slice_range: [35,115]                                                #  Slices to use for training IXI data.
#slice_range: [2,16]                                               # Slices to use for training MRNet data.
                                  #Load checkpoint
load_cp: 0                                                          # 0 to start a new training or checkpoint path to load network weights.
resume_training: 1                                                  # 0 - Load only model weights , 1 - Load Weights + epoch number + optimizer and scheduler state.

                                  #Networks parameters
bilinear: 0                                                         # 1 - Use bilinear upsampling , 0 - Use up-conv.
crop_center: 128                                                    # Discriminator center crop size (128X128), to avoid classifying blank patches.

                                # Swin-Transformer
num_classes: 1
patch_size: 4
in_chans: 6
embed_dim: 96
depths: [2, 2, 6, 2]
num_heads: [3, 6, 12, 24]
window_size: 8
mlp_ratio: 4.
qkv_bias: True
qk_scale: None
drop_rate: 0.0
drop_path_rate: 0.1
ape: False
patch_norm: True
use_checkpoint: False

                                  #Training parameters
lr: 0.001                                                           # Learning rate default: 0.001
epochs_n: 50                                                   # Number of epochs
batch_size: 12                                                     # Batch size. Reduce if out of memory.Batch size of 32 256X256 images needs ~13GB memory.
GAN_training: 1                                                     # 1 - Use GAN training. 0 - No GAN (no discriminator training and adverserial loss)
loss_weights: [1000, 1000, 5, 0.1, 0]                          # Loss weighting [Imspac L2, Imspace L1, Kspace L2, GAN_Loss, FFL ]. Losses are weighted to be roughly at the same scale.
minmax_noise_val: [-0.01, 0.01]

                                  #Tensorboard
tb_write_losses: 1                                                  # Write losses and scalars to Tensorboard.
tb_write_images: 0                                                  # Write images to Tensorboard.

                                  #Runtime
device: 'cpu'                                                      # For GPU training : 'cuda', for CPU training (not recomended!) 'cpu'.
gpu_id: '0'                                                         # GPU ID to use.
train_num_workers: 0                                               # Number of training dataset workers. Reduce if you are getting a shared memory error.
val_num_workers: 0                                                  # Number of validation dataset workers. Reduce if you are getting a shared memory error.

                                 #Predict parameters
save_prediction: 0                                                  # Save predicted images.
save_path: "SAVE_path"                                              # Path to save predictions
visualize_images: 0                                                 # Visualize predicted images.0
#model: "OUTPUT_PATH/IXI_results/Gaussian2D_8x_33.21_0.9082_diffusion_VVT/CP_epoch30.pth"                                             # Model checkpoint to use for prediction.
model: "OUTPUT_PATH/CP_epoch34.pth"
#model: "C:/Users/zx/Desktop/code/Subsampled-Brain-MRI-Reconstruction-by-Generative-Adversarial-Neural-Networks-master/OUTPUT_PATH/a/30%/12.26/CP_epoch50.pth"
predict_data_dir: "data/h5_2013/test"                                   # Test set files dir, should contain hdf5 preprocessed data.

                                  #Additional Parameters
GP: True
ST: True
iRPE: False                         #True means add irpe